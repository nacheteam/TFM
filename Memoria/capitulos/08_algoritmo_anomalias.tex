\chapter{Algoritmo de detección de anomalías}
\label{chapter:algoritmo-anomalias}

El capítulo anterior ha tratado sobre los modelos que se han implementado. Estos algoritmos lo que hacen es tomar unos datos normales como entrada, entrenar y luego evaluar unos datos de test. Tras evaluar los datos de test lo que tenemos son scores de anomalías, es decir, para cada instancia del conjunto de test tenemos una puntuación. Con esta puntuación por sí sola no tenemos ningún tipo de detección, lo que tenemos que hacer es utilizar estas puntuaciones para alimentar algún algoritmo que detecte los eventos anómalos.

Cuando estemos ante eventos normales tendremos puntuaciones bajas, mientras que si estamos ante eventos anómalos tendremos puntuaciones más altas. En este sentido podemos pensar en las puntuaciones como en una serie temporal uno dimensional, en la que queremos hallar los puntos en los que destaca por la subida en el score por encima de los niveles normales.

Para esto lo primero que vamos a hacer es pasar los datos de tipo numérico a categórico, es decir, cuándo tenemos una anomalía y cuando estamos ante un dato normal. Para ello se ha elaborado un sistema de cotas que permite establecer un punto a partir del cual dejamos de considerar dicho dato como normal y lo empezamos a considerar anómalo.

El sistema basa su comportamiento en dos cotas, una cota general y otra cota local. La cota general es pasada como un parámetro externo, en nuestro caso hemos reservado unos cuantos días para calcular la cota global de forma que no empleemos los datos de test para esto. La cota general puede ser calculada de muchas formas, en nuestro caso se han probado la media de las puntuaciones, la media mas tres desviaciones típicas, la mediana, el percentil 95 y la mediana mas tres desviaciones típicas. De esta forma la metodología seguida es, reservamos de los 468 días en total de nuestro conjunto de datos los primeros días para entrenamiento de las redes neuronales, dejando los dos últimos meses para cálculo de cotas y el conjunto de test. De estos dos últimos meses el primero de ellos será para cálculo de cotas y el segundo como test. Esto nos deja aproximadamente dos millones y medio de instancias de test.

Una vez dicho esto, lo primero que vamos a describir es el algoritmo que convierte los scores en clases. Vamos a ir pasando una ventana deslizante por los datos de un tiempo definido previamente, en este caso 3 horas de datos. Esta ventana la vamos a dividir en dos partes, la primera va a ser para calcular una cota local, para lo cual emplearemos la media mas 3 desviaciones típicas. Esta cota local se va a combinar con la cota global haciendo una media. La intención de esta cota cambiante es que podamos ajustarnos un poco mejor a los datos que tenemos, si tenemos unos datos muy anómalos y estos persisten mucho tiempo, puede que haya un cambio de concepto en las puntuaciones de anomalía. Por otro lado la cota global introducida nos da un mínimo que deben cumplir nuestras puntuaciones para ser consideradas anómalas y mantiene el algoritmo estable.

Ya tenemos la cota total, generada a partir de la cota global y la cota local. Tras estos datos que hemos empleado para el cálculo de la cota local, vamos a emplear dicha cota para ver si los puntos la sobrepasan o no. En caso de que la sobrepasen marcamos los puntos con un uno, en caso contrario con un cero. De esta forma, al final del proceso, vamos a tener los puntos etiquetados como anómalos o normales en función del comportamiento que tienen local y globalmente con respecto a su puntuación.

Una vez que tenemos los puntos etiquetados como anómalos o normales, tenemos que determinar cuándo un periodo de tiempo es anómalo o no. Pensemos de la siguiente forma: tenemos los datos de un día completo ya etiquetados con ceros y unos en función de si las instancias son normales o anómalas. Teniendo esto podemos pasar una ventana deslizante por estos datos e ir viendo si tenemos suficientes puntos dentro anómalos como para considerar esta ventana deslizante anómala o no. 

Haciendo esto lo que vamos a tener al final es un conjunto de ventanas que consideramos anómalas y por tanto daríamos la alarma a los operarios si nos encontrásemos en una de estas ventanas deslizantes. Lo siguiente que necesitamos saber es cuándo vamos a considerar que lo estamos haciendo bien y cuándo lo estamos haciendo mal, es decir, cuando tenemos un verdadero positivo y cuándo tenemos un falso positivo. 

Desde la empresa, se nos dijo que lo más interesante era intentar predecir un mantenimiento en la franja temporal previa al mismo. En concreto se nos trasladó que lo más lógico es que no fuese ni mucho tiempo ni poco tiempo para que se pudiera asociar a algo concreto y que no fuese demasiado tarde para arreglarlo. Por ello se fijó que tendríamos un verdadero positivo si obteníamos una ventana anómala en la franja de 6 horas previas a un mantenimiento. Si tenemos una alerta en cualquier momento previo a dicha franja tendremos por tanto un falso positivo.

Por otro lado debemos decidir el número de datos que queremos procesar en estas ventanas deslizantes. Tiene que ser un número suficiente como para analizar el comportamiento local pero que no sea demasiado pequeña, ya que no obtendríamos demasiada información. Se decidió que ventanas deslizantes de dos horas con solapamiento de una hora era un tamaño interesante y válido para este fin.

Por tanto ya tenemos el tamaño de la ventana deslizante, el solapamiento y cuándo consideramos que tenemos un falso positivo y un verdadero positivo. Ahora nos falta decidir cuándo vamos a decir que tenemos una ventana anómala y por tanto debemos dar la alarma. En este caso se decidió que un porcentaje razonable de anomalías era un cinco por ciento. Esto quiere decir que si tenemos menos de un 5\% de anomalías en nuestra ventana no vamos a dar la alarma, pero si superamos o igualamos este porcentaje entonces marcaremos dicha ventana como anómala.

Con todos estos parámetros ya tenemos todo lo que necesitamos. Vamos a ir deslizando una ventana de dos horas con solapamiento de una hora, si en dicha ventana se supera el 5\% de anomalías entonces marcamos la ventana. Si esta ventana se encuentra dentro del intervalo de seis horas previas a un mantenimiento estamos ante un verdadero positivo, si no se encuentra en esta franja temporal estamos ante un falso positivo.

Con esto dicho podemos sacar tres métricas importantes e interesantes para nuestro problema: los verdaderos positivos, los falsos positivos y los mantenimientos que detectamos sobre el total presentes en el conjunto de test. Con esto hemos convertido un problema no supervisado, con etiquetas poco concretas en un problema más definido sobre el que podemos sacar algunas métricas.

Como añadido a todo esto, se añade la posibilidad de eliminar las anomalías puntuales que más nos puedan alterar la clasificación de las mismas en normales o anómalas. Por ello se añade como parámetro para probar el saturar las puntuaciones de anomalías que superen el percentil 99, cambiándolas por la mediana del score del resto de datos. Esto es un parámetro más a probar por lo que se ha estudiado todo el sistema haciendo esta saturación y sin hacerla.