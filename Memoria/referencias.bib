
@misc{juanjo_nieto_apuntes_2018,
	title = {Apuntes Modelos Matemáticos 2},
	url = {https://www.ugr.es/~jjmnieto/docencia-files/Apuntes_sin_verficar_parte_I.pdf},
	author = {{Juanjo Nieto} and {Antonia Delgado}},
	date = {2018},
	langid = {spanish},
	note = {00000}
}

@inproceedings{gao_converting_2006,
	title = {Converting output scores from outlier detection algorithms into probability estimates},
	pages = {212--221},
	booktitle = {Sixth International Conference on Data Mining ({ICDM}'06)},
	publisher = {{IEEE}},
	author = {Gao, Jing and Tan, Pang-Ning},
	date = {2006},
	file = {2006-Gao-Converting_output_scores_from_outlier_detection_algorithms_into_probability.pdf:/home/nacheteam/Zotero/storage/4IWNQIDB/2006-Gao-Converting_output_scores_from_outlier_detection_algorithms_into_probability.pdf:application/pdf}
}

@book{yaser_learning_2012,
	title = {Learning from Data: a short course},
	url = {https://work.caltech.edu/telecourse.html},
	shorttitle = {Learning from Data},
	pagetotal = {215},
	author = {Yaser, Abu-Mostafa and Malik, Magdon-Ismail and Hsuan-Tien, Lin},
	date = {2012},
	langid = {english}
}

@book{cherkassky_learning_2007,
	title = {Learning from Data: Concepts, Theory, and Methods},
	isbn = {978-0-470-14051-2},
	shorttitle = {Learning from Data},
	abstract = {An interdisciplinary framework for learning methodologies—covering statistics, neural networks, and fuzzy logic, this book provides a unified treatment of the principles and methods for learning dependencies from data. It establishes a general conceptual framework in which various learning methods from statistics, neural networks, and fuzzy logic can be applied—showing that a few fundamental principles underlie most new methods being proposed today in statistics, engineering, and computer science. Complete with over one hundred illustrations, case studies, and examples making this an invaluable text.},
	pagetotal = {558},
	publisher = {John Wiley \& Sons},
	author = {Cherkassky, Vladimir and Mulier, Filip M.},
	date = {2007-09-10},
	langid = {english},
	note = {02476},
	keywords = {Computers / Data Modeling \& Design, Technology \& Engineering / Electrical}
}

@book{aggarwal_outlier_2017,
	location = {New York},
	title = {Outlier Analysis},
	isbn = {978-1-4614-6395-5},
	url = {//www.springer.com/us/book/9781461463955},
	abstract = {With the increasing advances in hardware technology for data collection, and advances in software technology (databases) for data organization, computer scientists have increasingly participated in the latest advancements of the outlier analysis field. Computer scientists, specifically, approach this field based on their practical experiences in managing large amounts of data, and with far fewer assumptions– the data can be of any type, structured or unstructured, and may be extremely large. Outlier Analysis is a comprehensive exposition, as understood by data mining experts, statisticians and computer scientists. The book has been organized carefully, and emphasis was placed on simplifying the content, so that students and practitioners can also benefit. Chapters will typically cover one of three areas: methods and techniques commonly used in outlier analysis, such as linear methods, proximity-based methods, subspace methods, and supervised methods; data domains, such as, text, categorical, mixed-attribute, time-series, streaming, discrete sequence, spatial and network data; and key applications of these methods as applied to diverse domains such as credit card fraud detection, intrusion detection, medical diagnosis, earth science, web log analytics, and social network analysis are covered.},
	publisher = {Springer-Verlag},
	author = {Aggarwal, Charu C.},
	urldate = {2018-03-20},
	date = {2017},
	langid = {english},
	file = {2017-Aggarwal-Outlier_Analysis.pdf:/home/nacheteam/Zotero/storage/ZTSLAHSQ/2017-Aggarwal-Outlier_Analysis.pdf:application/pdf}
}

@inproceedings{aggarwal_outlier_2001,
	location = {New York, {NY}, {USA}},
	title = {Outlier Detection for High Dimensional Data},
	isbn = {978-1-58113-332-5},
	url = {http://doi.acm.org/10.1145/375663.375668},
	doi = {10.1145/375663.375668},
	series = {{SIGMOD} '01},
	abstract = {The outlier detection problem has important applications in the field of fraud detection, network robustness analysis, and intrusion detection. Most such applications are high dimensional domains in which the data can contain hundreds of dimensions. Many recent algorithms use concepts of proximity in order to find outliers based on their relationship to the rest of the data. However, in high dimensional space, the data is sparse and the notion of proximity fails to retain its meaningfulness. In fact, the sparsity of high dimensional data implies that every point is an almost equally good outlier from the perspective of proximity-based definitions. Consequently, for high dimensional data, the notion of finding meaningful outliers becomes substantially more complex and non-obvious. In this paper, we discuss new techniques for outlier detection which find the outliers by studying the behavior of projections from the data set.},
	pages = {37--46},
	booktitle = {Proceedings of the 2001 {ACM} {SIGMOD} International Conference on Management of Data},
	publisher = {{ACM}},
	author = {Aggarwal, Charu C. and Yu, Philip S.},
	urldate = {2019-03-13},
	date = {2001},
	note = {event-place: Santa Barbara, California, {USA}},
	file = {2001-Aggarwal-Outlier_Detection_for_High_Dimensional_Data.pdf:/home/nacheteam/Zotero/storage/WKS4QWQL/2001-Aggarwal-Outlier_Detection_for_High_Dimensional_Data.pdf:application/pdf}
}

@book{m_loeve_probability_1977,
	title = {Probability Theory},
	publisher = {Springer-Verlag},
	author = {M. Loève},
	date = {1977},
	note = {00032}
}

@book{hastie_t_elements_nodate,
	title = {The elements of Statistical Learning: Data Mining Inference and Prediction},
	publisher = {New York: Springer},
	author = {{Hastie T.} and {R. Tibshirani} and {J. Friedman}},
	note = {44014}
}

@book{vapnik_v_nature_nodate,
	title = {The Nature of Statistical Learning Theory},
	publisher = {New York: Springer},
	author = {Vapnik V.},
	langid = {english},
	note = {00049}
}

@book{goodfellow_deep_2016,
	title = {Deep Learning},
	pagetotal = {800},
	publisher = {The {MIT} Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	date = {2016}
}

@article{zhao_pyod_2019,
	title = {{PyOD}: A Python Toolbox for Scalable Outlier Detection},
	url = {http://arxiv.org/abs/1901.01588},
	shorttitle = {{PyOD}},
	abstract = {{PyOD} is an open-source Python toolbox for performing scalable outlier detection on multivariate data. Uniquely, it provides access to a wide range of outlier detection algorithms, including established outlier ensembles and more recent neural network-based approaches, under a single, well-documented {API} designed for use by both practitioners and researchers. With robustness and scalability in mind, best practices such as unit testing, continuous integration, code coverage, maintainability checks, interactive examples and parallelization are emphasized as core components in the toolbox's development. {PyOD} is compatible with both Python 2 and 3 and can be installed through Python Package Index ({PyPI}) or https://github.com/yzhao062/pyod.},
	journaltitle = {{arXiv}:1901.01588 [cs, stat]},
	author = {Zhao, Yue and Nasrullah, Zain and Li, Zheng},
	urldate = {2019-01-30},
	date = {2019-01-06},
	eprinttype = {arxiv},
	eprint = {1901.01588},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Information Retrieval},
	file = {2019-Zhao-PyOD.pdf:/home/nacheteam/Zotero/storage/K5VQKQUL/2019-Zhao-PyOD.pdf:application/pdf}
}

@article{ander_analyzing_2019,
	title = {Analyzing rare event, anomaly, novelty and outlier detection terms under the supervised classification framework},
	journaltitle = {Artificial Intelligence Review, Springer Nature},
	author = {Ander, Carreño and Iñaki, Inza and Jose A., Lozano},
	date = {2019}
}

@misc{aguilera_martos_deteccion_2019,
	title = {Detección de Anomalías Basada en Técnicas de Ensembles},
	url = {https://github.com/nacheteam/TFG/blob/master/Memoria/TFG-Ignacio%20Aguilera%20Martos.pdf},
	author = {Aguilera Martos, Ignacio},
	date = {2019}
}

@article{fabian_keller_hics_2012,
	title = {{HiCS}: High Constrast Subspaces for Density-Based Outlier Ranking},
	url = {https://ieeexplore.ieee.org/document/6228154},
	doi = {10.1109/ICDE.2012.88},
	abstract = {Outlier mining is a major task in data analysis. Outliers are objects that highly deviate from regular objects in their local neighborhood. Density-based outlier ranking methods score each object based on its degree of deviation. In many applications, these ranking methods degenerate to random listings due to low contrast between outliers and regular objects. Outliers do not show up in the scattered full space, they are hidden in multiple high contrast subspace projections of the data. Measuring the contrast of such subspaces for outlier rankings is an open research challenge. In this work, we propose a novel subspace search method that selects high contrast subspaces for density-based outlier ranking. It is designed as pre-processing step to outlier ranking algorithms. It searches for high contrast subspaces with a significant amount of conditional dependence among the subspace dimensions. With our approach, we propose a first measure for the contrast of subspaces. Thus, we enhance the quality of traditional outlier rankings by computing outlier scores in high contrast projections only. The evaluation on real and synthetic data shows that our approach outperforms traditional dimensionality reduction techniques, naive random projections as well as state-of-the-art subspace search techniques and provides enhanced quality for outlier ranking.},
	pages = {12},
	author = {Fabian Keller and Emmanuel Müller and Klemens Böhm},
	date = {2012},
	langid = {english},
	note = {00000}
}

@book{giancarlo_deep_2017,
	title = {Deep Learning with {TensorFlow}},
	publisher = {Packt},
	author = {Giancarlo, Zaccone and Md. Rezaul, Karim and Ahmed, Menshawy},
	date = {2017}
}

@article{david_practical_2018,
	title = {A practical tutorial on autoencoders for nonlinear feature fusion: Taxonomy, models, software and guidelines},
	journaltitle = {Information Fusion},
	author = {David, Charte and Francisco, Charte and Salvador, García and María J.º, del Jesus and Francisco, Herrera},
	date = {2018}
}

@article{lu_expressive_2017,
	title = {The Expressive Power of Neural Networks: A View from the Width},
	pages = {6231--6239},
	journaltitle = {Curran Associates Inc.},
	author = {Lu, Zhou and Pu, Hongming and Wang, Feicheng and Hu, Zhiqiang and Wang, Liwei},
	date = {2017}
}

@article{tae_young_predicting_2019,
	title = {Predicting residential energy consumption using {CNN}-{LSTM} neural networks},
	volume = {182},
	issn = {0360-5442},
	url = {http://www.sciencedirect.com/science/article/pii/S0360544219311223},
	doi = {https://doi.org/10.1016/j.energy.2019.05.230},
	pages = {72--81},
	journaltitle = {Energy},
	author = {Tae Young, Kim and Sung Bae, Cho},
	date = {2019}
}

@article{lih_oh_automated_2018,
	title = {Automated diagnosis of arrhythmia using combination of {CNN} and {LSTM} techniques with variable length heart beats},
	volume = {102},
	issn = {0010-4825},
	url = {http://www.sciencedirect.com/science/article/pii/S0010482518301446},
	doi = {https://doi.org/10.1016/j.compbiomed.2018.06.002},
	pages = {278--287},
	journaltitle = {Computers in Biology and Medicine},
	author = {Lih Oh, Shu and Y. K. Ng, Eddie and San Tan, Ru and Rajendra Acharya, U.},
	date = {2018}
}

@article{he_discovering_2003,
	title = {Discovering cluster-based local outliers},
	volume = {24},
	pages = {1641--1650},
	number = {9},
	journaltitle = {Pattern Recognition Letters},
	author = {He, Zengyou and Xu, Xiaofei and Deng, Shengchun},
	date = {2003}
}

@article{goldstein_histogram-based_2012,
	title = {Histogram-based Outlier Score ({HBOS}): A fast Unsupervised Anomaly Detection Algorithm},
	author = {Goldstein, Markus and Dengel, Andreas},
	date = {2012}
}

@article{hawkings_outlier_2002,
	title = {Outlier Detection Using Replicator Neural Networks},
	author = {Hawkings, S. and He, H. and Williams, G. and Baxter, R.},
	date = {2002}
}

@article{liu_isolation_2008,
	title = {Isolation Forest},
	pages = {413--422},
	journaltitle = {{IEE}},
	author = {Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua},
	date = {2008}
}

@article{samaswamy_efficient_2000,
	title = {Efficient Algorithms for Mining Outliers from Large Data Sets},
	volume = {29},
	url = {https://doi.org/10.1145/335191.335437},
	doi = {10.1145/335191.335437},
	pages = {427--438},
	number = {2},
	journaltitle = {Association for Computing Machinery},
	author = {Samaswamy, Sridhar and Rastogi, Rajeev and Shim, Kyuseok},
	date = {2000}
}

@article{tomas_loda_2016,
	title = {Loda: Lightweight on-Line Detector of Anomalies},
	volume = {102},
	url = {https://doi.org/10.1007/s10994-015-5521-0},
	doi = {10.1007/s10994-015-5521-0},
	pages = {275--304},
	number = {2},
	journaltitle = {Kluwer Academic Publishers},
	author = {Tomas, Pevny},
	date = {2016}
}

@article{mei-ling_novel_2003,
	title = {A novel anomaly detection scheme based on principal component classifier},
	author = {Mei-Ling, Shyu and Shu-Ching, Cheng and Kanoksri, Sarinnapakorn and Liwu, Chang},
	date = {2003}
}

@article{markus_m_lof_2000,
	title = {{LOF}: identifying density-based local outliers},
	pages = {93--104},
	journaltitle = {Proceedings of the 2000 {ACM} {SIGMOD} international conference on Management of data},
	author = {Markus M, Breuning and Hans-Peter, Kriegel and Raymond T, Ng and Sander, Jorg},
	date = {2000}
}

@article{lazarevic_feature_2005,
	title = {Feature Bagging for Outlier Detection},
	url = {https://doi.org/10.1145/1081870.1081891},
	doi = {10.1145/1081870.1081891},
	journaltitle = {Association for Computing Machinery},
	author = {Lazarevic, Aleksandar and Kumar, Vipin},
	date = {2005}
}

@article{zahra_should_2019,
	title = {Should I rise the red flag? A comprehensive survey of anomaly scoring methods toward mitigating false alarms},
	author = {Zahra, Zohrevand and Uwe, Glässer},
	date = {2019}
}

@book{aggarwal_outlier_2017-1,
	title = {Outlier Ensembles},
	author = {Aggarwal, Charu C. and Sathe, Saket},
	date = {2017}
}